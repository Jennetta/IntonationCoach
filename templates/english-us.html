{% extends 'base.html' %}
{% block body %}

<style>
.chart svg {
  height: 400px;
}

.nvd3 g.nv-groups path.nv-line {
  stroke-width: 4px;
}
</style>


<div class="container-fluid">

	<h1>English (US)</h1>
	<br>
	<p>Paragraph introducing the common intonation patterns.</p>
	<br>

  <p>Example sentence 1</p>
  <button type="button" class="btn btn-primary" id="play-en-us-1">Play</button>
  <br><br>
  <p>Now try to repeat with the same intonation:</p>
  <button type="button" class="btn btn-danger record en-us-1">Record</button>
  <button type="button" class="btn btn-primary play-back en-us-1">Play back</button>
  <button type="button" class="btn btn-default analyze en-us-1">Compare!</button>
    <div class="loading en-us-1" style="display: inline-block"><img src="../static/img/loading-wheel.gif" height="35px" />
    </div>
  <br><br>

<div class="chart en-us-1">
  <svg></svg>
</div>

  <p>Example sentence 2</p>
  <button type="button" class="btn btn-primary" id="play-en-us-2">Play</button>
  <br><br>
  <p>Now try to repeat with the same intonation:</p>
  <button type="button" class="btn btn-danger record en-us-2">Record</button>
  <button type="button" class="btn btn-primary play-back en-us-2">Play back</button>
  <button type="button" class="btn btn-default analyze en-us-2">Compare!</button>
    <div class="loading en-us-2" style="display: inline-block"><img src="../static/img/loading-wheel.gif" height="35px" />
    </div>
  <br><br>

<div class="chart en-us-2">
  <svg></svg>
</div>


</div>



<script>

// Audio player setup

var buf = null;

//create AudioContext
var context = new AudioContext;

//load and decode wav file
function loadFile(url) { 
    var request = new XMLHttpRequest(); 
    request.open("GET", url, true); 
    request.responseType = "arraybuffer"; 
    request.onload = function() { 
        //decode the loaded data 
        context.decodeAudioData(request.response, function(buffer) { 
            buf = buffer;
            // call playSound() once buffer is loaded
            playSound();
        }); 
    }; 
    request.send(); 
} 

//play the loaded file 
function playSound() { 
    //create a source node from the buffer 
    var src = context.createBufferSource();  
    src.buffer = buf; 
    //connect to the final output node (the speakers) 
    src.connect(context.destination); 
    //play immediately 
    src.start(0); 
} 


// set up recorder (using Recorder.js)

var recorder;
var userRecUrl;
var userBlob;

function startUserMedia(stream) {
  var input = context.createMediaStreamSource(stream);
  recorder = new Recorder(input);
}

window.onload = function init() {
  navigator.getUserMedia = ( navigator.getUserMedia ||
                       navigator.webkitGetUserMedia ||
                       navigator.mozGetUserMedia ||
                       navigator.msGetUserMedia);

  navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
      console.log('Error: ', e);
    });
};

// create object url for blob when exportWAV is called
function myCallback(blob) {
  userRecUrl = (window.URL || window.webkitURL).createObjectURL(blob);
  userBlob = blob;
}


// change appearance & function of buttons in response to user actions
function handleRecord(exID) {
  if ($('.record.'+exID).html() == "Record") {

    recorder.record();
    $('.record.'+exID).html("Stop");
  } else {
    recorder.stop();
    recorder.exportWAV(myCallback);

    $('.record.'+exID).html("Record");
    $('.analyze.'+exID).removeAttr('disabled');
    $('.play-back.'+exID).removeAttr('disabled');
  }
};

// send user's recording & sentence id to server, assign pitch data from response to variables, update graph
function showUserPitch(blob, targetPitchData, exID) {
  $('.loading.'+exID).show();
  var reader = new FileReader();
  // this is triggered once the blob is read and readAsDataURL returns
  reader.onload = function (event) {
    var formData = new FormData();
    formData.append('user_rec', event.target.result);
    $.ajax({
      type: "POST",
      url: '/analyze',
      data: formData, 
      processData: false,
      contentType: false,
      dataType: 'json',
      cache: false,
      success: function(response) {
        var userPitchData = JSON.parse(response['user']);
        updateGraph(targetPitchData, userPitchData, exID);
      }
    });
  }
  reader.readAsDataURL(blob);

  recorder.clear();
};
  
var chart

// build graph with NVD3
function buildGraph(targetPitchData, exID) {
  nv.addGraph(function() {
    chart = nv.models.lineChart()
      .useInteractiveGuideline(true)
      .interpolate("basis")
      .forceX([0, 2.0]);      // replace 2.0 with length of recording

    chart.xAxis
      .axisLabel('Time (s)')
      .tickFormat(d3.format(',.1f'));

    chart.yAxis
      .axisLabel('Pitch (Hz)')
      .tickFormat(d3.format(',d'));

    d3.select('.chart.'+exID+' svg')
      .datum(targetData(targetPitchData))
      .transition().duration(500)
      .call(chart);

    nv.utils.windowResize(chart.update);

    return chart;
  });
}

function updateGraph(targetPitchData, userPitchData, exID) {
  d3.select('.chart.'+exID+' svg')
    .datum(allData(targetPitchData, userPitchData))
    .transition().duration(500);

    chart.update();
    $('.loading').hide();
}

function targetData(targetPitchData) {
  return [
    {
      values: targetPitchData,
      key: 'Sample recording'
    }
  ];
}

function allData(targetPitchData, userPitchData) {
  return [
    {
      values: targetPitchData,
      key: 'Sample recording'
    },
    {
      values: userPitchData,
      key: 'Your recording',
      color: '#ff7f0e'
    }
  ];
}

$('.loading').hide();

// when loading page: for each sentence, get target pitch data and build graph
$(document).ready(function() {
  var numExamples = 2;    // set this to number of example sentences on page
  for (var i = 1; i < (numExamples + 1); i++) {
    $.post('/targetdata', { sentence: 'supermarche' }, function(response) {
      var targetPitchData = JSON.parse(response['target']);
      exID = 'en-us-'+i
      buildGraph(targetPitchData, exID);
    })
  };
});


// when play button is pressed, play sample sentence & animate play bar across graph
$('#play-en-us-1').on('click', function(evt) {
  loadFile("/sounds/supermarche2.wav");
  // create playbar
  var svg = d3.select('.chart.en-us-1 svg');
  var playBar = svg.append("line")
    .attr("x1", 60)
    .attr("y1", 20)
    .attr("x2", 60)
    .attr("y2", 500)
    .attr("stroke-width", 1)
    .attr("stroke", "black");
  // animate playbar
  playBar.transition()
    .attr("x1", 1120)   // sub in width of graph
    .attr("x2", 1120)   // " " "
    .duration(2000)     // sub in length of recording
    .ease("linear")
    .transition()
      .delay(2000)      // length of recording again
      .duration(200)
      .remove();
});

$('.play-back').on('click', function(evt) {
  loadFile(userRecUrl);
});

// disable playback & compare buttons until user has recorded
$('.play-back').attr('disabled','disabled');
$('.analyze').attr('disabled','disabled');

// when Record/Stop button is pressed
$('.record').on('click', function(evt) {
  exID = $(this).attr("class").split(' ')[3];
  console.log("record/stop", exID);
  handleRecord(exID);
});

// when Compare button is pressed, analyze user's recording & show graph
$('.analyze').on('click', function(evt) {
  exID = $(this).attr("class").split(' ')[3];
  console.log("analyze", exID);
  showUserPitch(userBlob, exID);
});

</script>

{% endblock %}