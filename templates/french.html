{% extends 'base.html' %}
{% block body %}

<div class="container-fluid">

	<h1>French</h1>
	<br>
	<p>Paragraph introducing the common intonation patterns in French.</p>
	<br>

  <p>Example sentence 1</p>
  <button type="button" class="btn btn-primary" id="play-sample1">Play</button>
  <br><br>
  <p>Now try to repeat with the same intonation:</p>
  <button type="button" class="btn btn-danger" id="record">Record</button>
  <button type="button" class="btn btn-primary" id="play-back">Play back</button>
  <button type="button" class="btn btn-default" id="analyze">Compare!</button>
  <!-- TODO: make Compare button unpressable until a recording is started & stopped -->
  <br><br>

</div>

<figure style="width: 1000px; height: 500px" id="pitch-contour"></figure>


<script>

// Audio player setup

var buf = null;

//create AudioContext
var context = new AudioContext;

//load and decode wav file - can't use ajax bc it doesn't support responseType?
function loadFile(url) { 
    var request = new XMLHttpRequest(); 
    request.open("GET", url, true); 
    request.responseType = "arraybuffer"; 
    request.onload = function() { 
        //decode the loaded data 
        context.decodeAudioData(request.response, function(buffer) { 
            buf = buffer;
            // call playSound() once buffer is loaded
            playSound();
        }); 
    }; 
    request.send(); 
} 

//play the loaded file 
function playSound() { 
    //create a source node from the buffer 
    var src = context.createBufferSource();  
    src.buffer = buf; 
    //connect to the final output node (the speakers) 
    src.connect(context.destination); 
    //play immediately 
    src.start(0); 
} 


// set up recorder (using Recorder.js)

var recorder;
var userRecUrl;
var userBlob;

function startUserMedia(stream) {
  var input = context.createMediaStreamSource(stream);
  recorder = new Recorder(input);
}

window.onload = function init() {
  navigator.getUserMedia = ( navigator.getUserMedia ||
                       navigator.webkitGetUserMedia ||
                       navigator.mozGetUserMedia ||
                       navigator.msGetUserMedia);

  navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
      console.log('Error: ', e);
    });
};

// create object url for blob when exportWAV is called
function myCallback(blob) {
  userRecUrl = (window.URL || window.webkitURL).createObjectURL(blob);
  userBlob = blob;
}


// change appearance & function of buttons in response to user actions
function handleRecord() {
  if ($('#record').html() == "Record") {

    recorder.record();
    $('#record').html("Stop");
  } else {
    recorder.stop();
    recorder.exportWAV(myCallback);

    $('#record').html("Record");
    $('#analyze').removeAttr('disabled');
    $('#play-back').removeAttr('disabled');
  }
};

// send user's recording & sentence id to server, assign pitch data from response to variables, build graph
function showAnalysis(sentenceID, blob) {
  var reader = new FileReader();
  // this is triggered once the blob is read and readAsDataURL returns
  reader.onload = function (event) {
    var formData = new FormData();
    formData.append('sentence', sentenceID);
    formData.append('user_rec', event.target.result);
    $.ajax({
      type: "POST",
      url: '/analyze',
      data: formData, 
      processData: false,
      contentType: false,
      dataType: 'json',
      cache: false,
      success: function(response) {
        var targetPitchData = JSON.parse(response['target']);
        var userPitchData = JSON.parse(response['user']);
        buildGraph(targetPitchData, userPitchData);
      }
    });
  }
  reader.readAsDataURL(blob);

  recorder.clear();
};
  
function buildGraph(target, user) {
  
  var data = {
    "xScale": "linear",
    "yScale": "linear",
    "type": "line",
    "main": [
      {
        "className": ".target",
        "data": target
      },
      {
        "className": ".user",
        "data": user
      }
    ]
  };

  var opts = {
    "axisPaddingRight": 0,
    "axisPaddingLeft": 0
  };

  var myChart = new xChart('line', data, '#pitch-contour', opts);

  // unhide graph
  $('#pitch-contour').show();
}



// play sample sentence when play button is pressed
$('#play-sample1').on('click', function(evt) {
  loadFile("/sounds/supermarche2.wav");
});

$('#play-back').on('click', function(evt) {
  loadFile(userRecUrl);
});

// hide graph until user has submitted recording
$('#pitch-contour').hide();

// disable playback & compare buttons until user has recorded
$('#play-back').attr('disabled','disabled');
$('#analyze').attr('disabled','disabled');

// when Record/Stop button is pressed
$('#record:not(.stop-btn)').on('click', handleRecord);

// when Compare button is pressed, analyze user's recording & show graph
$('#analyze').on('click', function(evt) {
  showAnalysis('supermarche', userBlob);
});

</script>

{% endblock %}